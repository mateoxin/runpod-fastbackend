#!/usr/bin/env python3
"""
Test RunPod Serverless Endpoint
Testuje utworzony endpoint z RTX 3090
"""

import runpod
import os
import json
import time
from dotenv import load_dotenv

def load_endpoint_info():
    """Åaduje informacje o endpoint"""
    try:
        with open('endpoint_info.json', 'r') as f:
            return json.load(f)
    except FileNotFoundError:
        print("âŒ Nie znaleziono endpoint_info.json")
        return None

def test_endpoint():
    """Testuje endpoint"""
    # Åaduj konfiguracjÄ™
    load_dotenv('config.env')
    runpod.api_key = os.getenv('RUNPOD_API_KEY')
    
    endpoint_info = load_endpoint_info()
    if not endpoint_info:
        return
    
    endpoint_id = endpoint_info['id']
    endpoint_url = endpoint_info['url']
    
    print(f"ğŸš€ Testowanie Endpoint: {endpoint_info['name']}")
    print(f"ğŸ†” ID: {endpoint_id}")
    print(f"ğŸ”— URL: {endpoint_url}")
    print(f"ğŸ–¥ï¸  GPU: {endpoint_info['gpu_type']} ({endpoint_info['gpu_memory']})")
    print("=" * 50)
    
    # Test 1: Health Check
    print("\nğŸ§ª Test 1: Health Check")
    try:
        # Inicjalizuj endpoint
        endpoint = runpod.Endpoint(endpoint_id)
        
        # WyÅ›lij test job
        test_payload = {
            "input": {
                "type": "health",
                "message": "Test RTX 3090 endpoint"
            }
        }
        
        print(f"ğŸ“¤ WysyÅ‚anie payload: {test_payload}")
        
        # Uruchom job
        run_request = endpoint.run_sync(test_payload, timeout=120)
        
        if run_request:
            print(f"âœ… Health check PASSED")
            print(f"ğŸ“‹ Response: {json.dumps(run_request, indent=2)}")
        else:
            print("âŒ Health check FAILED - brak response")
            
    except Exception as e:
        print(f"âŒ Health check ERROR: {e}")
    
    # Test 2: Ping Test
    print("\nğŸ§ª Test 2: Ping Test")
    try:
        ping_payload = {
            "input": {
                "type": "ping"
            }
        }
        
        print(f"ğŸ“¤ WysyÅ‚anie ping payload...")
        run_request = endpoint.run_sync(ping_payload, timeout=60)
        
        if run_request:
            print(f"âœ… Ping test PASSED")
            print(f"ğŸ“ Ping Response: {json.dumps(run_request, indent=2)}")
        else:
            print("âŒ Ping test FAILED")
            
    except Exception as e:
        print(f"âŒ Ping test ERROR: {e}")
    
    # Test 3: Echo Test
    print("\nğŸ§ª Test 3: Echo Test")
    try:
        echo_payload = {
            "input": {
                "type": "echo",
                "test_data": "RTX 3090 endpoint test",
                "gpu_type": "NVIDIA GeForce RTX 3090",
                "timestamp": time.time()
            }
        }
        
        print(f"ğŸ“¤ WysyÅ‚anie echo payload...")
        run_request = endpoint.run_sync(echo_payload, timeout=60)
        
        if run_request:
            print(f"âœ… Echo test PASSED")
            print(f"ğŸ”„ Echo Response: {json.dumps(run_request, indent=2)}")
        else:
            print("âŒ Echo test FAILED")
            
    except Exception as e:
        print(f"âŒ Echo test ERROR: {e}")
    
    # Test 4: Environment Setup
    print("\nğŸ§ª Test 4: Environment Setup Test")
    try:
        setup_payload = {
            "input": {
                "type": "setup_environment"
            }
        }
        
        print(f"ğŸ“¤ Uruchamianie setup environment... (moÅ¼e potrwaÄ‡ 2-3 minuty)")
        run_request = endpoint.run_sync(setup_payload, timeout=300)  # 5 min timeout
        
        if run_request:
            print(f"âœ… Environment setup COMPLETED")
            print(f"ğŸ”§ Setup Response: {json.dumps(run_request, indent=2)}")
        else:
            print("âŒ Environment setup FAILED")
            
    except Exception as e:
        print(f"âŒ Environment setup ERROR: {e}")
    
    # Test 5: List Models
    print("\nğŸ§ª Test 5: List Models Test")
    try:
        models_payload = {
            "input": {
                "type": "list_models"
            }
        }
        
        print(f"ğŸ“¤ Sprawdzanie dostÄ™pnych modeli...")
        run_request = endpoint.run_sync(models_payload, timeout=120)
        
        if run_request:
            print(f"âœ… List models PASSED")
            print(f"ğŸ“ Models Response: {json.dumps(run_request, indent=2)}")
        else:
            print("âŒ List models FAILED")
            
    except Exception as e:
        print(f"âŒ List models ERROR: {e}")

def check_endpoint_status():
    """Sprawdza status endpoint"""
    load_dotenv('config.env')
    runpod.api_key = os.getenv('RUNPOD_API_KEY')
    
    endpoint_info = load_endpoint_info()
    if not endpoint_info:
        return
    
    print(f"ğŸ“Š Sprawdzanie statusu endpoint...")
    
    try:
        endpoints = runpod.get_endpoints()
        for endpoint in endpoints:
            if endpoint.get('id') == endpoint_info['id']:
                print(f"âœ… Endpoint znaleziony:")
                print(f"   ğŸ“› Name: {endpoint.get('name', 'Unknown')}")
                print(f"   ğŸ†” ID: {endpoint.get('id', 'Unknown')}")
                print(f"   ğŸ“ˆ Status: {endpoint.get('status', 'Unknown')}")
                print(f"   ğŸ‘¥ Workers: {endpoint.get('workersMax', 'Unknown')} max")
                print(f"   ğŸŒ Locations: {endpoint.get('locations', 'Unknown')}")
                return endpoint
        
        print("âŒ Endpoint nie znaleziony")
        return None
        
    except Exception as e:
        print(f"âŒ BÅ‚Ä…d sprawdzania statusu: {e}")
        return None

def main():
    """GÅ‚Ã³wna funkcja testowa"""
    print("ğŸ§ª RunPod Endpoint Tester")
    print("=========================")
    
    # SprawdÅº status endpoint
    endpoint_status = check_endpoint_status()
    
    if not endpoint_status:
        print("âŒ Nie moÅ¼na kontynuowaÄ‡ bez statusu endpoint")
        return
    
    # SprawdÅº czy endpoint jest gotowy
    status = endpoint_status.get('status', 'Unknown')
    if status not in ['READY', 'ACTIVE'] and status != 'Unknown':
        print(f"âš ï¸  Endpoint nie jest gotowy (status: {status})")
        print("ğŸ’¡ Endpoint moÅ¼e potrzebowaÄ‡ wiÄ™cej czasu na uruchomienie.")
        print("   SprÃ³buj ponownie za kilka minut.")
        return
    
    if status == 'Unknown':
        print(f"âš ï¸  Status endpoint: {status} - prÃ³bujemy testowaÄ‡...")
        print("ğŸ’¡ Endpoint moÅ¼e byÄ‡ w trakcie uruchamiania, ale sprÃ³bujemy poÅ‚Ä…czenia.")
    
    # Uruchom testy
    test_endpoint()
    
    print("\nğŸ‰ Testy zakoÅ„czone!")
    print("ğŸ“‹ Podsumowanie testÃ³w:")
    print("   âœ… Health check - podstawowy test poÅ‚Ä…czenia")
    print("   âœ… Ping test - test responsywnoÅ›ci") 
    print("   âœ… Echo test - test przesyÅ‚ania danych")
    print("   âœ… Environment setup - instalacja PyTorch/ML libs")
    print("   âœ… Models listing - sprawdzenie dostÄ™pnych modeli")
    print("")
    print("ğŸ–¥ï¸  Endpoint RTX 3090 Details:")
    print("   - GPU: NVIDIA GeForce RTX 3090 (24GB VRAM)")
    print("   - Storage: 100GB container + 100GB volume")
    print("   - Max workers: 2 (quota limit)")
    print("   - Wszystkie zmienne Å›rodowiskowe skonfigurowane")

if __name__ == "__main__":
    main()