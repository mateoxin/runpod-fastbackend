# ğŸš€ GitHub to RunPod Deployment Guide

**DokÅ‚adna instrukcja wdroÅ¼enia FastBackend z GitHub na RunPod Serverless**

---

## ğŸ“‹ **WYMAGANIA**

### âœ… **Gotowe pliki w repo:**
- `handler_fast.py` - gÅ‚Ã³wny handler âœ…
- `handler.py` - entry point dla RunPod âœ…
- `Dockerfile` - definicja obrazu Docker âœ…
- `requirements.txt` - dependencies âœ…
- `requirements_minimal.txt` - minimal deps âœ…

### ğŸ”§ **Konto i dostÄ™py:**
- Konto RunPod z API key
- Repository GitHub (publiczne lub private)
- Opcjonalnie: Docker Hub account

---

## ğŸ¯ **METODA 1: DEPLOYMENT PRZEZ RUNPOD CONSOLE (ZALECANE)**

### Krok 1: Przygotowanie Repository
```bash
# Upewnij siÄ™ Å¼e masz najnowszÄ… wersjÄ™
git pull origin master

# SprawdÅº czy wszystkie pliki sÄ… commitowane
git status
```

### Krok 2: RunPod Console Setup
1. **IdÅº do**: https://runpod.io/console
2. **Zaloguj siÄ™** na swoje konto RunPod
3. **PrzejdÅº do**: `Serverless` â†’ `Endpoints`
4. **Kliknij**: `Create Endpoint`

### Krok 3: Konfiguracja Endpoint
```
ğŸ”§ KONFIGURACJA:
â”œâ”€â”€ Name: "FastBackend-Matt"
â”œâ”€â”€ Source: "GitHub"
â”œâ”€â”€ Repository: "mateoxin/runpod-fastbackend"
â”œâ”€â”€ Branch: "master"
â”œâ”€â”€ Handler: "handler.handler"  # lub "handler_fast.handler"
â”œâ”€â”€ Docker: Use automatic Dockerfile
â””â”€â”€ Environment Variables: (patrz sekcja poniÅ¼ej)
```

### Krok 4: Environment Variables
```bash
# WYMAGANE:
HF_TOKEN=your_huggingface_token_here
PYTHONUNBUFFERED=1

# OPCJONALNE:
WORKSPACE_PATH=/workspace
MODEL_CACHE_DIR=/workspace/models
TRAINING_DATA_PATH=/workspace/training_data
```

### Krok 5: Resource Configuration
```
ğŸ“Š ZASOBY:
â”œâ”€â”€ GPU Type: "NVIDIA RTX A6000" (lub RTX 4090)
â”œâ”€â”€ GPU Count: 1
â”œâ”€â”€ Container Disk: 50 GB
â”œâ”€â”€ Volume: 100 GB (dla modeli i danych)
â”œâ”€â”€ Min Workers: 0
â”œâ”€â”€ Max Workers: 3
â”œâ”€â”€ Idle Timeout: 5 minutes
â””â”€â”€ Locations: EU-SE-1, US-CA-1
```

### Krok 6: Deploy
1. **SprawdÅº konfiguracjÄ™**
2. **Kliknij**: `Deploy`
3. **Czekaj** ~2-5 minut na deployment
4. **SprawdÅº status** w Console

---

## ğŸ¯ **METODA 2: DEPLOYMENT PRZEZ RUNPOD API**

### Krok 1: Przygotuj API Key
```bash
export RUNPOD_API_KEY="your_api_key_here"
```

### Krok 2: Deploy z API
```bash
curl -X POST https://api.runpod.ai/v2/endpoints \\
  -H "Authorization: Bearer ${RUNPOD_API_KEY}" \\
  -H "Content-Type: application/json" \\
  -d '{
    "name": "FastBackend-Matt",
    "template_id": null,
    "gpu_type_id": "NVIDIA RTX A6000",
    "container_disk_in_gb": 50,
    "volume_in_gb": 100,
    "workers_min": 0,
    "workers_max": 3,
    "idle_timeout": 300,
    "locations": "EU-SE-1,US-CA-1",
    "docker_start_cmd": null,
    "env": {
      "HF_TOKEN": "your_huggingface_token_here",
      "PYTHONUNBUFFERED": "1"
    },
    "github": {
      "repo": "mateoxin/runpod-fastbackend",
      "branch": "master",
      "handler": "handler.handler"
    }
  }'
```

---

## ğŸ¯ **METODA 3: DOCKER IMAGE DEPLOYMENT**

### Krok 1: Build Local Image
```bash
# W folderze projektu
docker build --platform linux/amd64 -t mateoxin/fastbackend:latest .
```

### Krok 2: Push do Docker Hub
```bash
docker login
docker push mateoxin/fastbackend:latest
```

### Krok 3: Deploy Image na RunPod
```bash
# W RunPod Console:
# Source: Docker Image
# Image: mateoxin/fastbackend:latest
# Handler: handler.handler
```

---

## ğŸ§ª **TESTOWANIE DEPLOYMENT**

### Test 1: Health Check
```bash
curl -X POST https://api.runpod.ai/v2/YOUR_ENDPOINT_ID/run \\
  -H "Authorization: Bearer YOUR_API_KEY" \\
  -H "Content-Type: application/json" \\
  -d '{"input": {"type": "health"}}'
```

**Oczekiwany wynik:**
```json
{
  "id": "job-id-12345",
  "status": "IN_QUEUE"
}
```

### Test 2: SprawdÅº Status
```bash
curl -X GET https://api.runpod.ai/v2/YOUR_ENDPOINT_ID/status/job-id-12345 \\
  -H "Authorization: Bearer YOUR_API_KEY"
```

**Oczekiwany wynik:**
```json
{
  "status": "COMPLETED",
  "output": {
    "status": "healthy",
    "message": "Fast backend is working!",
    "environment_ready": false,
    "version": "1.0.0-fast"
  }
}
```

### Test 3: Setup Environment
```bash
curl -X POST https://api.runpod.ai/v2/YOUR_ENDPOINT_ID/run \\
  -H "Authorization: Bearer YOUR_API_KEY" \\
  -H "Content-Type: application/json" \\
  -d '{"input": {"type": "setup_environment"}}'
```

### Test 4: Upload Matt Dataset
```bash
# Ten test uÅ¼ywa prawdziwych zdjÄ™Ä‡ z tests/10_Matt/
curl -X POST https://api.runpod.ai/v2/YOUR_ENDPOINT_ID/run \\
  -H "Authorization: Bearer YOUR_API_KEY" \\
  -H "Content-Type: application/json" \\
  -d '{"input": {"type": "upload_training_data", "files": [...]}}'
```

---

## ğŸ”§ **TESTOWANIE LOKALNE**

### Test Input (jak w dokumentacji RunPod)
```bash
python handler_fast.py --test_input '{"input": {"type": "health"}}'
```

### Local API Server (jak w dokumentacji RunPod)
```bash
# Zainstaluj dependencies
pip install fastapi uvicorn

# Uruchom local server
python handler_fast.py --rp_serve_api

# Testuj w innym terminalu
curl -X POST http://localhost:8000/run \\
  -H "Content-Type: application/json" \\
  -d '{"input": {"type": "health"}}'
```

---

## ğŸ› **TROUBLESHOOTING**

### Problem 1: "Handler not found"
```bash
# SprawdÅº handler path:
# Powinno byÄ‡: "handler.handler" lub "handler_fast.handler"
# W RunPod Console: Endpoint â†’ Settings â†’ Handler
```

### Problem 2: "Import Error"
```bash
# SprawdÅº requirements.txt
# Upewnij siÄ™ Å¼e runpod>=1.7.0 jest w dependencies
```

### Problem 3: "Timeout podczas startup"
```bash
# ZwiÄ™ksz timeout w endpoint settings
# Lub przenieÅ› heavy setup poza handler
```

### Problem 4: "Payload too large"
```bash
# SprawdÅº rozmiar requestu:
# /run: max 10MB
# /runsync: max 20MB
```

### Problem 5: "GPU Memory Error"
```bash
# ZwiÄ™ksz GPU type lub container disk
# RTX A6000: 48GB VRAM
# RTX 4090: 24GB VRAM
```

---

## ğŸ“Š **MONITORING DEPLOYMENT**

### RunPod Console
```
ğŸ–¥ï¸ Console â†’ Serverless â†’ Your Endpoint:
â”œâ”€â”€ ğŸ“ˆ Metrics: requests, latency, errors
â”œâ”€â”€ ğŸ“‹ Logs: real-time worker logs
â”œâ”€â”€ âš™ï¸ Settings: scaling, timeouts
â””â”€â”€ ğŸ’° Billing: usage costs
```

### API Monitoring
```bash
# Endpoint health
curl -X GET https://api.runpod.ai/v2/YOUR_ENDPOINT_ID/health \\
  -H "Authorization: Bearer YOUR_API_KEY"

# Worker status
curl -X GET https://api.runpod.ai/v2/YOUR_ENDPOINT_ID/workers \\
  -H "Authorization: Bearer YOUR_API_KEY"
```

---

## âœ… **CHECKLIST PRZED DEPLOYMENT**

### Pre-deployment
- [ ] Wszystkie pliki w repo (handler_fast.py, Dockerfile, requirements.txt)
- [ ] Repository na GitHub zaktualizowane
- [ ] RunPod API key gotowy
- [ ] HuggingFace token gotowy
- [ ] GPU type wybrany

### Post-deployment
- [ ] Health check dziaÅ‚a
- [ ] Setup environment dziaÅ‚a
- [ ] Upload test data dziaÅ‚a
- [ ] Logs bez bÅ‚Ä™dÃ³w w Console
- [ ] Billing/costs sÄ… rozsÄ…dne

---

## ğŸ‰ **GOTOWE!**

**TwÃ³j FastBackend bÄ™dzie dostÄ™pny pod:**
```
Endpoint URL: https://api.runpod.ai/v2/YOUR_ENDPOINT_ID/run
API Key: YOUR_RUNPOD_API_KEY
```

**Do treningu LoRA z zdjÄ™ciami Matta:**
1. Upload zdjÄ™Ä‡ z `tests/10_Matt/`
2. Setup environment
3. Train z `training.yaml`
4. Download wytrenowanego modelu

**WiÄ™cej:** https://docs.runpod.io/serverless/overview