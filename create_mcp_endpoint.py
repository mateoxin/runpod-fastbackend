#!/usr/bin/env python3
"""
Tworzenie RunPod Endpoint przez MCP
Z RTX 3090 i 100GB dysku
"""

import runpod
import os
import json
import time
from dotenv import load_dotenv
from datetime import datetime

def setup_runpod():
    """Konfiguracja RunPod"""
    load_dotenv('config.env')
    runpod.api_key = os.getenv('RUNPOD_API_KEY')
    
    if not runpod.api_key:
        raise ValueError("RUNPOD_API_KEY nie jest ustawiony!")
    
    print(f"‚úÖ RunPod API skonfigurowany: {runpod.api_key[:10]}...")
    return True

def create_improved_template():
    """Tworzy lepszy template z optymalizacjami"""
    
    # Zmienne ≈õrodowiskowe dla endpoint
    env_vars = {
        'RUNPOD_API_KEY': os.getenv('RUNPOD_API_KEY'),
        'HF_TOKEN': os.getenv('HF_TOKEN'), 
        'GITHUB_TOKEN': os.getenv('GITHUB_TOKEN'),
        'PYTHONUNBUFFERED': '1',
        'HANDLER_FILE': 'handler_fast.py',
        'CUDA_VISIBLE_DEVICES': '0',
        'NVIDIA_VISIBLE_DEVICES': 'all',
        'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility',
        'TORCH_CUDA_ARCH_LIST': '8.6',  # RTX 3090 architecture
        'MAX_WORKERS': '1',
        'TIMEOUT': '600',  # 10 min timeout
        'MEMORY_LIMIT': '100G'
    }
    
    print("\nüìã Tworzenie ulepszonego template...")
    print("üîß Konfiguracja:")
    print("   - Image: PyTorch 2.1.0 + CUDA 11.8")
    print("   - Container Disk: 100GB")
    print("   - Volume: 100GB") 
    print("   - GPU: RTX 3090 optimized")
    print(f"   - Env vars: {len(env_vars)}")
    
    try:
        template_response = runpod.create_template(
            name='fastbackend-rtx3090-v2-template',
            image_name='runpod/pytorch:2.1.0-py3.10-cuda11.8.0-devel-ubuntu22.04',
            docker_start_cmd='python3 handler_fast.py',
            container_disk_in_gb=100,  # 100GB container disk
            volume_in_gb=100,          # 100GB volume
            volume_mount_path='/workspace',
            ports='8000/http,22/tcp',
            env=env_vars,
            is_serverless=True
        )
        
        if template_response:
            template_id = template_response.get('id')
            print(f"‚úÖ Template v2 utworzony: {template_id}")
            return template_id
        else:
            print("‚ùå B≈ÇƒÖd tworzenia template")
            return None
            
    except Exception as e:
        print(f"‚ùå B≈ÇƒÖd: {e}")
        return None

def create_optimized_endpoint(template_id):
    """Tworzy zoptymalizowany endpoint"""
    
    print(f"\nüöÄ Tworzenie zoptymalizowanego endpoint...")
    print("üìä Parametry:")
    print("   - GPU: RTX 3090 (24GB VRAM)")
    print("   - Template: v2 (ulepszona)")
    print("   - Workers: 1 (stabilno≈õƒá)")
    print("   - Timeout: 10s (szybszy start)")
    print("   - Storage: 100GB")
    
    try:
        # Tworzenie endpoint z lepszymi parametrami
        response = runpod.create_endpoint(
            name='fastbackend-rtx3090-v2',
            template_id=template_id,
            gpu_ids='NVIDIA GeForce RTX 3090',
            locations='US,EU',        # Multi-region
            idle_timeout=10,          # 10s timeout (szybszy)
            scaler_type='QUEUE_DELAY',
            scaler_value=5,           # Szybsza reakcja
            workers_min=0,            # Auto-scale down
            workers_max=1,            # Maksymalnie 1 worker
            gpu_count=1,              # 1 GPU per worker
            flashboot=True            # Szybszy boot
        )
        
        if response:
            endpoint_id = response.get('id') if isinstance(response, dict) else response
            
            print(f"\n‚úÖ Nowy endpoint utworzony!")
            print(f"üÜî ID: {endpoint_id}")
            print(f"üìõ Name: fastbackend-rtx3090-v2")
            print(f"üîó URL: https://api.runpod.ai/v2/{endpoint_id}")
            
            # Zapisz nowe informacje
            endpoint_info = {
                'id': endpoint_id,
                'name': 'fastbackend-rtx3090-v2',
                'url': f'https://api.runpod.ai/v2/{endpoint_id}',
                'template_id': template_id,
                'gpu_type': 'NVIDIA GeForce RTX 3090',
                'gpu_memory': '24GB',
                'container_disk_gb': 100,
                'volume_gb': 100,
                'workers_max': 1,
                'idle_timeout': 10,
                'flashboot': True,
                'version': 'v2',
                'created_at': datetime.now().isoformat(),
                'status': 'creating'
            }
            
            # Zapisz do pliku
            with open('endpoint_v2_info.json', 'w') as f:
                json.dump(endpoint_info, f, indent=2)
            
            print(f"üíæ Informacje zapisane w endpoint_v2_info.json")
            return endpoint_id
            
        else:
            print("‚ùå B≈ÇƒÖd tworzenia endpoint")
            return None
            
    except Exception as e:
        print(f"‚ùå B≈ÇƒÖd endpoint: {e}")
        return None

def cleanup_old_endpoint():
    """Usuwa problematyczny stary endpoint"""
    
    print(f"\nüßπ Sprawdzanie starych endpoints...")
    
    try:
        endpoints = runpod.get_endpoints()
        old_endpoint_id = '6vi641zor1txhn'  # Stary problematyczny endpoint
        
        for endpoint in endpoints:
            if endpoint.get('id') == old_endpoint_id:
                print(f"üóëÔ∏è  Znaleziono stary endpoint: {old_endpoint_id}")
                print(f"   Name: {endpoint.get('name', 'Unknown')}")
                print(f"   Status: {endpoint.get('status', 'Unknown')}")
                
                # Zatrzymaj endpoint (mo≈ºna te≈º usunƒÖƒá)
                choice = input("Czy zatrzymaƒá stary endpoint? (y/n): ").lower()
                if choice == 'y':
                    try:
                        # U≈ºyj runpod API do zatrzymania
                        print(f"‚èπÔ∏è  Zatrzymywanie endpoint {old_endpoint_id}...")
                        # runpod.delete_endpoint(old_endpoint_id)  # Uncomment to delete
                        print(f"‚úÖ Endpoint {old_endpoint_id} zostanie zatrzymany")
                    except Exception as e:
                        print(f"‚ùå B≈ÇƒÖd zatrzymywania: {e}")
                break
        else:
            print("‚ÑπÔ∏è  Stary endpoint nie znaleziony lub ju≈º usuniƒôty")
            
    except Exception as e:
        print(f"‚ùå B≈ÇƒÖd sprawdzania endpoints: {e}")

def wait_for_endpoint_ready(endpoint_id, timeout=300):
    """Czeka a≈º endpoint bƒôdzie gotowy"""
    
    print(f"\n‚è≥ Czekanie na uruchomienie endpoint {endpoint_id}...")
    print("üí° To mo≈ºe potrwaƒá 2-5 minut...")
    
    start_time = time.time()
    
    while time.time() - start_time < timeout:
        try:
            endpoints = runpod.get_endpoints()
            for endpoint in endpoints:
                if endpoint.get('id') == endpoint_id:
                    status = endpoint.get('status', 'Unknown')
                    print(f"üìä Status: {status}")
                    
                    if status in ['READY', 'ACTIVE']:
                        print(f"‚úÖ Endpoint gotowy! Status: {status}")
                        return True
                    elif status in ['FAILED', 'ERROR']:
                        print(f"‚ùå Endpoint ma b≈ÇƒÖd! Status: {status}")
                        return False
                    
                    break
            
            print("‚è≥ Sprawdzanie ponownie za 30s...")
            time.sleep(30)
            
        except Exception as e:
            print(f"‚ö†Ô∏è  B≈ÇƒÖd sprawdzania statusu: {e}")
            time.sleep(30)
    
    print(f"‚ö†Ô∏è  Timeout - endpoint mo≈ºe nadal siƒô uruchamiaƒá")
    return False

def main():
    """G≈Ç√≥wna funkcja"""
    print("üöÄ RunPod MCP Endpoint Creator v2")
    print("==================================")
    print("üéØ Cel: RTX 3090 + 100GB + Stabilno≈õƒá")
    print("")
    
    # Setup RunPod
    if not setup_runpod():
        return
    
    # Utw√≥rz nowy template
    template_id = create_improved_template()
    if not template_id:
        print("‚ùå Nie uda≈Ço siƒô utworzyƒá template")
        return
    
    # Utw√≥rz nowy endpoint
    endpoint_id = create_optimized_endpoint(template_id)
    if not endpoint_id:
        print("‚ùå Nie uda≈Ço siƒô utworzyƒá endpoint")
        return
    
    # Opcjonalnie posprzƒÖtaj stary endpoint
    cleanup_old_endpoint()
    
    # Czekaj na gotowo≈õƒá
    print(f"\nüéØ Nowy endpoint RTX 3090 v2 utworzony!")
    print(f"üÜî ID: {endpoint_id}")
    print(f"üìÅ Szczeg√≥≈Çy w: endpoint_v2_info.json")
    print("")
    print("üìã Nastƒôpne kroki:")
    print("1. Poczekaj 2-5 minut na uruchomienie")
    print("2. Uruchom: python test_v2_endpoint.py")
    print("3. Przetestuj wszystkie funkcje")

if __name__ == "__main__":
    main()